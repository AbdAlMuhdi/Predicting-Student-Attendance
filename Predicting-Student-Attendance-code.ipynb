{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "from sklearn.impute import SimpleImputer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_binary(df, column_name):\n",
    "    #Check if a column has only two unique values.\n",
    "    return len(df[column_name].unique()) == 2\n",
    "\n",
    "\n",
    "def is_string(df, column_name):\n",
    "    #Check if a column contains non-numeric values.\n",
    "    for i in df[column_name]:\n",
    "        if not str(i).isdigit():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def convert_binary_to_numeric(df, column_name):\n",
    "    #Convert binary categorical columns to numeric values (0/1).\n",
    "    unique_values = df[column_name].unique()\n",
    "    if set(unique_values) == set(['Yes', 'No']):\n",
    "        value_map = {\"No\": 0, \"Yes\": 1}\n",
    "    else:\n",
    "        value_map = {val: idx for idx, val in enumerate(unique_values)}\n",
    "    \n",
    "    df[column_name] = df[column_name].apply(lambda x: value_map[x])\n",
    "    print(f\"The binary column \\\"{column_name}\\\" is mapped based on: {value_map}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_columns(df):\n",
    "    #Label encode non-numeric and binary categorical columns.\n",
    "    label_encoder = LabelEncoder()\n",
    "    df_encoded = df.copy()\n",
    "\n",
    "    for column in df.columns:\n",
    "        if is_string(df, column):\n",
    "            if is_binary(df, column):\n",
    "                df_encoded = convert_binary_to_numeric(df_encoded, column)\n",
    "            else:\n",
    "                df_encoded[column] = label_encoder.fit_transform(df[column])\n",
    "                # Print the mapping between original categories and encoded labels\n",
    "                mapping = dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))\n",
    "                print(f\"Mapping for column {column}: {mapping}\")\n",
    "        else:\n",
    "            df_encoded[column] = df[column]\n",
    "    \n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Training and Evaluation\n",
    "def evaluate_model(classifier, X, y, k_splits=5):\n",
    "    #Evaluate a classifier using KFold cross-validation and print confusion matrices.\n",
    "    kf = KFold(n_splits=k_splits, shuffle=True)\n",
    "    conf_matrices = []\n",
    "    reports = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        # Fit the classifier\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Compute confusion matrix and classification report\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        report_matrix = classification_report(y_test, y_pred)\n",
    "        \n",
    "        conf_matrices.append(conf_matrix)\n",
    "        reports.append(report_matrix)\n",
    "    \n",
    "    # Display confusion matrices and reports for each fold\n",
    "    for i, conf_matrix in enumerate(conf_matrices):\n",
    "        print(f\"Fold {i+1}\")\n",
    "        print(f\"Classification Report:\\n{reports[i]}\")\n",
    "        print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def holdout_evaluation(classifier, X_train, X_test, y_train, y_test):\n",
    "    #Evaluate a classifier on holdout test data.\n",
    "    classifier.fit(X_train, y_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    # Print classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"Classification Report:\\n{report}\")\n",
    "    print(f\"Confusion Matrix:\\n{conf_matrix}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample_data(X, y):\n",
    "    #Perform SMOTE oversampling on the dataset.\n",
    "    oversampler = SMOTE(random_state=42)\n",
    "    X_over, y_over = oversampler.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"Original class distribution: {Counter(y)}\")\n",
    "    print(f\"Oversampled class distribution: {Counter(y_over)}\")\n",
    "    \n",
    "    return X_over, y_over\n",
    "\n",
    "\n",
    "def undersample_data(X, y):\n",
    "    #Perform Random undersampling on the dataset.\n",
    "    undersampler = RandomUnderSampler(random_state=42)\n",
    "    X_under, y_under = undersampler.fit_resample(X, y)\n",
    "    \n",
    "    print(f\"Original class distribution: {Counter(y)}\")\n",
    "    print(f\"Undersampled class distribution: {Counter(y_under)}\")\n",
    "    \n",
    "    return X_under, y_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization Functions\n",
    "def plot_histogram(df, column, title):\n",
    "    #Plot a histogram for a categorical column.\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.hist(df[column], bins=len(df[column].unique()), color='skyblue', edgecolor='black')\n",
    "    plt.title(title)\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(axis='y')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Responses.csv')\n",
    "    \n",
    "df = df.drop(['Family_Issues', \"University_Activities\", \"Teams\",\"Timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary column \"Sex\" is mapped based on: {'M': 0, 'F': 1}\n",
      "Mapping for column University: {'AAB': 0, 'AAU': 1, 'AHU': 2, 'AMAU': 3, 'ASU': 4, 'AUM': 5, 'BAUM': 6, 'GJU': 7, 'HTU': 8, 'HU': 9, 'INU': 10, 'IU': 11, 'JU': 12, 'JUST': 13, 'MEU': 14, 'MU': 15, 'PSUT': 16, 'TTU': 17, 'UOP': 18, 'WISE': 19, 'YU': 20, 'ZU': 21, 'ZUJ': 22, 'esrs.unrwa': 23, 'jadara': 24}\n",
      "Mapping for column collage: {'Allied Medical Sciences': 0, 'Arts and Design': 1, 'Business': 2, 'Childhood': 3, 'Dentistry': 4, 'Educational Sciences': 5, 'Engineering': 6, 'Foreign Languages': 7, 'Information Technology': 8, 'Literature': 9, 'Mathematics': 10, 'Medicine': 11, 'Natural Resources': 12, 'Nursing': 13, 'Pharmacy': 14, 'Rights': 15, 'Science': 16, 'Sharia': 17, 'Tourism': 18}\n",
      "Mapping for column Hour_fees: {'(10 - 40) JD': 0, '(45 - 80) JD': 1, '(80+) JD': 2}\n",
      "Mapping for column Grade: {'A': 0, 'B': 1, 'C': 2, 'D': 3}\n",
      "The binary column \"Absence\" is mapped based on: {'No': 0, 'Yes': 1}\n",
      "The binary column \"teacher_interest\" is mapped based on: {'No': 0, 'Yes': 1}\n",
      "The binary column \"external_sources\" is mapped based on: {'No': 0, 'Yes': 1}\n",
      "The binary column \"Friends\" is mapped based on: {'No': 0, 'Yes': 1}\n",
      "The binary column \"Friends_Absence\" is mapped based on: {'No': 0, 'Yes': 1}\n"
     ]
    }
   ],
   "source": [
    "df_encoded = encode_categorical_columns(df)\n",
    "X = df_encoded.drop(columns=['Absence'])\n",
    "y = df_encoded['Absence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train-test sets for holdout validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Decision Tree Classifier:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.56      0.57       183\n",
      "           1       0.70      0.72      0.71       262\n",
      "\n",
      "    accuracy                           0.66       445\n",
      "   macro avg       0.64      0.64      0.64       445\n",
      "weighted avg       0.65      0.66      0.66       445\n",
      "\n",
      "Confusion Matrix:\n",
      "[[103  80]\n",
      " [ 73 189]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.68      0.65       186\n",
      "           1       0.75      0.71      0.73       258\n",
      "\n",
      "    accuracy                           0.70       444\n",
      "   macro avg       0.69      0.69      0.69       444\n",
      "weighted avg       0.70      0.70      0.70       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[126  60]\n",
      " [ 75 183]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.61      0.59       176\n",
      "           1       0.73      0.71      0.72       268\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.66      0.66      0.66       444\n",
      "weighted avg       0.67      0.67      0.67       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  69]\n",
      " [ 77 191]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63       181\n",
      "           1       0.75      0.70      0.72       263\n",
      "\n",
      "    accuracy                           0.68       444\n",
      "   macro avg       0.68      0.68      0.68       444\n",
      "weighted avg       0.69      0.68      0.69       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[120  61]\n",
      " [ 79 184]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.65      0.60       166\n",
      "           1       0.77      0.69      0.72       278\n",
      "\n",
      "    accuracy                           0.67       444\n",
      "   macro avg       0.66      0.67      0.66       444\n",
      "weighted avg       0.69      0.67      0.68       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[108  58]\n",
      " [ 87 191]]\n",
      "\n",
      "Evaluating Naive Bayes Classifier:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.70      0.69       177\n",
      "           1       0.80      0.79      0.79       268\n",
      "\n",
      "    accuracy                           0.75       445\n",
      "   macro avg       0.74      0.74      0.74       445\n",
      "weighted avg       0.75      0.75      0.75       445\n",
      "\n",
      "Confusion Matrix:\n",
      "[[124  53]\n",
      " [ 57 211]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.64      0.64       184\n",
      "           1       0.75      0.76      0.75       260\n",
      "\n",
      "    accuracy                           0.71       444\n",
      "   macro avg       0.70      0.70      0.70       444\n",
      "weighted avg       0.71      0.71      0.71       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[117  67]\n",
      " [ 62 198]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.75      0.73       196\n",
      "           1       0.79      0.77      0.78       248\n",
      "\n",
      "    accuracy                           0.76       444\n",
      "   macro avg       0.76      0.76      0.76       444\n",
      "weighted avg       0.76      0.76      0.76       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[147  49]\n",
      " [ 58 190]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.70      0.70       176\n",
      "           1       0.80      0.81      0.81       268\n",
      "\n",
      "    accuracy                           0.77       444\n",
      "   macro avg       0.76      0.75      0.75       444\n",
      "weighted avg       0.77      0.77      0.77       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[123  53]\n",
      " [ 51 217]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       159\n",
      "           1       0.81      0.80      0.80       285\n",
      "\n",
      "    accuracy                           0.75       444\n",
      "   macro avg       0.73      0.73      0.73       444\n",
      "weighted avg       0.75      0.75      0.75       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  52]\n",
      " [ 58 227]]\n",
      "\n",
      "Evaluating KNN Classifier:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.54      0.57       171\n",
      "           1       0.73      0.78      0.75       274\n",
      "\n",
      "    accuracy                           0.69       445\n",
      "   macro avg       0.67      0.66      0.66       445\n",
      "weighted avg       0.68      0.69      0.68       445\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 92  79]\n",
      " [ 60 214]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65       174\n",
      "           1       0.77      0.80      0.78       270\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.72      0.71      0.72       444\n",
      "weighted avg       0.73      0.73      0.73       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[110  64]\n",
      " [ 55 215]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.61      0.65       196\n",
      "           1       0.72      0.80      0.76       248\n",
      "\n",
      "    accuracy                           0.71       444\n",
      "   macro avg       0.71      0.70      0.70       444\n",
      "weighted avg       0.71      0.71      0.71       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[119  77]\n",
      " [ 50 198]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.56      0.62       180\n",
      "           1       0.73      0.84      0.78       264\n",
      "\n",
      "    accuracy                           0.72       444\n",
      "   macro avg       0.72      0.70      0.70       444\n",
      "weighted avg       0.72      0.72      0.72       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[100  80]\n",
      " [ 43 221]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.54      0.58       171\n",
      "           1       0.73      0.79      0.76       273\n",
      "\n",
      "    accuracy                           0.69       444\n",
      "   macro avg       0.67      0.67      0.67       444\n",
      "weighted avg       0.69      0.69      0.69       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 93  78]\n",
      " [ 58 215]]\n",
      "\n",
      "Evaluating SVM Classifier:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.62      0.68       176\n",
      "           1       0.78      0.86      0.82       269\n",
      "\n",
      "    accuracy                           0.77       445\n",
      "   macro avg       0.76      0.74      0.75       445\n",
      "weighted avg       0.76      0.77      0.76       445\n",
      "\n",
      "Confusion Matrix:\n",
      "[[109  67]\n",
      " [ 37 232]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63       167\n",
      "           1       0.77      0.81      0.79       277\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.72      0.71      0.71       444\n",
      "weighted avg       0.73      0.73      0.73       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[101  66]\n",
      " [ 52 225]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.55      0.63       184\n",
      "           1       0.73      0.85      0.79       260\n",
      "\n",
      "    accuracy                           0.73       444\n",
      "   macro avg       0.73      0.70      0.71       444\n",
      "weighted avg       0.73      0.73      0.72       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[102  82]\n",
      " [ 38 222]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.64      0.66       168\n",
      "           1       0.79      0.82      0.80       276\n",
      "\n",
      "    accuracy                           0.75       444\n",
      "   macro avg       0.73      0.73      0.73       444\n",
      "weighted avg       0.75      0.75      0.75       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[107  61]\n",
      " [ 50 226]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.59      0.67       197\n",
      "           1       0.72      0.86      0.79       247\n",
      "\n",
      "    accuracy                           0.74       444\n",
      "   macro avg       0.75      0.72      0.73       444\n",
      "weighted avg       0.74      0.74      0.73       444\n",
      "\n",
      "Confusion Matrix:\n",
      "[[116  81]\n",
      " [ 35 212]]\n",
      "\n",
      "Holdout Evaluation for Decision Tree:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.59      0.59       178\n",
      "           1       0.73      0.73      0.73       267\n",
      "\n",
      "    accuracy                           0.67       445\n",
      "   macro avg       0.66      0.66      0.66       445\n",
      "weighted avg       0.67      0.67      0.67       445\n",
      "\n",
      "Confusion Matrix:\n",
      "[[105  73]\n",
      " [ 72 195]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize classifiers\n",
    "dt_classifier = DecisionTreeClassifier()\n",
    "nb_classifier = GaussianNB()\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "svm_classifier = SVC()\n",
    "    \n",
    "\n",
    "# Evaluate models with KFold cross-validation\n",
    "print(\"Evaluating Decision Tree Classifier:\")\n",
    "evaluate_model(dt_classifier, X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "print(\"Evaluating Naive Bayes Classifier:\")\n",
    "evaluate_model(nb_classifier, X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "print(\"Evaluating KNN Classifier:\")\n",
    "evaluate_model(knn_classifier, X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "print(\"Evaluating SVM Classifier:\")\n",
    "evaluate_model(svm_classifier, X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "    \n",
    "# Holdout evaluation\n",
    "print(\"Holdout Evaluation for Decision Tree:\")\n",
    "holdout_evaluation(dt_classifier, X_train, X_test, y_train, y_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({1: 1329, 0: 892})\n",
      "Oversampled class distribution: Counter({1: 1329, 0: 1329})\n",
      "Evaluating SVM Classifier with Oversampled Data:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       260\n",
      "           1       0.79      0.74      0.76       272\n",
      "\n",
      "    accuracy                           0.76       532\n",
      "   macro avg       0.76      0.76      0.76       532\n",
      "weighted avg       0.76      0.76      0.76       532\n",
      "\n",
      "Confusion Matrix:\n",
      "[[205  55]\n",
      " [ 71 201]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.78      0.75       269\n",
      "           1       0.76      0.69      0.72       263\n",
      "\n",
      "    accuracy                           0.74       532\n",
      "   macro avg       0.74      0.74      0.74       532\n",
      "weighted avg       0.74      0.74      0.74       532\n",
      "\n",
      "Confusion Matrix:\n",
      "[[210  59]\n",
      " [ 81 182]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.76      0.75       254\n",
      "           1       0.77      0.76      0.77       278\n",
      "\n",
      "    accuracy                           0.76       532\n",
      "   macro avg       0.76      0.76      0.76       532\n",
      "weighted avg       0.76      0.76      0.76       532\n",
      "\n",
      "Confusion Matrix:\n",
      "[[193  61]\n",
      " [ 68 210]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76       263\n",
      "           1       0.77      0.76      0.76       268\n",
      "\n",
      "    accuracy                           0.76       531\n",
      "   macro avg       0.76      0.76      0.76       531\n",
      "weighted avg       0.76      0.76      0.76       531\n",
      "\n",
      "Confusion Matrix:\n",
      "[[203  60]\n",
      " [ 65 203]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.81      0.79       283\n",
      "           1       0.77      0.74      0.75       248\n",
      "\n",
      "    accuracy                           0.77       531\n",
      "   macro avg       0.77      0.77      0.77       531\n",
      "weighted avg       0.77      0.77      0.77       531\n",
      "\n",
      "Confusion Matrix:\n",
      "[[228  55]\n",
      " [ 65 183]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform SMOTE oversampling\n",
    "X_over, y_over = oversample_data(X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "print(\"Evaluating SVM Classifier with Oversampled Data:\")\n",
    "evaluate_model(svm_classifier, X_over, y_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({1: 1329, 0: 892})\n",
      "Undersampled class distribution: Counter({0: 892, 1: 892})\n",
      "Evaluating SVM Classifier with Undersampled Data:\n",
      "Fold 1\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.79      0.74       170\n",
      "           1       0.78      0.67      0.72       187\n",
      "\n",
      "    accuracy                           0.73       357\n",
      "   macro avg       0.73      0.73      0.73       357\n",
      "weighted avg       0.74      0.73      0.73       357\n",
      "\n",
      "Confusion Matrix:\n",
      "[[135  35]\n",
      " [ 62 125]]\n",
      "\n",
      "Fold 2\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.75      0.74       176\n",
      "           1       0.75      0.73      0.74       181\n",
      "\n",
      "    accuracy                           0.74       357\n",
      "   macro avg       0.74      0.74      0.74       357\n",
      "weighted avg       0.74      0.74      0.74       357\n",
      "\n",
      "Confusion Matrix:\n",
      "[[132  44]\n",
      " [ 49 132]]\n",
      "\n",
      "Fold 3\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.73      0.73       182\n",
      "           1       0.72      0.73      0.72       175\n",
      "\n",
      "    accuracy                           0.73       357\n",
      "   macro avg       0.73      0.73      0.73       357\n",
      "weighted avg       0.73      0.73      0.73       357\n",
      "\n",
      "Confusion Matrix:\n",
      "[[133  49]\n",
      " [ 48 127]]\n",
      "\n",
      "Fold 4\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.73      0.71       174\n",
      "           1       0.73      0.69      0.71       183\n",
      "\n",
      "    accuracy                           0.71       357\n",
      "   macro avg       0.71      0.71      0.71       357\n",
      "weighted avg       0.71      0.71      0.71       357\n",
      "\n",
      "Confusion Matrix:\n",
      "[[127  47]\n",
      " [ 56 127]]\n",
      "\n",
      "Fold 5\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       190\n",
      "           1       0.71      0.67      0.69       166\n",
      "\n",
      "    accuracy                           0.72       356\n",
      "   macro avg       0.72      0.72      0.72       356\n",
      "weighted avg       0.72      0.72      0.72       356\n",
      "\n",
      "Confusion Matrix:\n",
      "[[144  46]\n",
      " [ 54 112]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform undersampling\n",
    "X_under, y_under = undersample_data(X.to_numpy(), y.to_numpy())\n",
    "    \n",
    "print(\"Evaluating SVM Classifier with Undersampled Data:\")\n",
    "evaluate_model(svm_classifier, X_under, y_under)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
